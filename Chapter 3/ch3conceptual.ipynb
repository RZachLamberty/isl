{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 3.4 represents the t-statistics and p-values of the coefficients generated in a linear regression of the `sales` response variable in the `Auto` data set to predictor factors `TV`, `radio`, and `newspaper` budgets.\n",
    "\n",
    "The t-statistic is a null hypothesis (coeff == 0?) measurement. It represents the number of standard deviations away from the null value (0) the regression coefficient was.\n",
    "\n",
    "The p-value is the integrated probability that a *true* 0 coefficient could, by random noise, result in that measured t-statistic.\n",
    "\n",
    "The actual values in Table 3.4 indicate the following:\n",
    "\n",
    "1. The intercept, the contribution from the `TV` budget, and the contribution from the `radio` budget are all statistically significant by the t-statistic null hypothesis test.\n",
    "  1. Based on coefficients, there is a strong response due to `radio` than `TV`\n",
    "2. The `newspaper` budget does not significantly affect the overall sales numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN *classifier* method is the application of KNN to predictors which result in a *qualitative* response\n",
    "\n",
    "The KNN *regression* method, on the other hand, is used for *quantitative* responses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Option (i) is correct -- With `IQ` and `GPA` fixed, we are looking at just the `Gender` component, and only $\\beta_3$ matters. a positive value for $\\beta_3$ means that there is an increase in salary associated with being a female ($\\beta_3\\cdot 1$), all other things considered (and it is more significant that the increase for `IQ` and `GPA`).\n",
    "2. $2,249.68 (see below for calculation)\n",
    "3. False -- we don't know enough to say that. There could be meaningful multicollinearity affects skewing these numbers, and there is no discussion as of yet about the relative certainty of any of the numbers in this model -- maybe we're including values that have non-negligible p-values, for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x, beta):\n",
    "    return sum(xi * betai for (xi, betai) in zip(x, beta))\n",
    "\n",
    "def x_from_stats(iq, gpa, gender):\n",
    "    return [1, iq, gpa, gender, iq * gpa, gender * gpa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2249.6800000000003"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = [50, 20, 0.07, 35, 0.01, -10]\n",
    "f(x_from_stats(110, 4.0, 1), beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If $Y = \\beta_0 + \\beta_1 X + \\epsilon$ is the true form of $Y$, I would expect the training RSS of the cubic form to be smaller. The extra terms will over-fit the noise, leading to a reduction of the overall residuals.\n",
    "2. The test RSS, on average, will be higher for the cubic fit. The higher-order coefficients arrived at in the cubic fit will have more to do with the noise from the test run than the actual functional form, so training data (which, presumably, has different and uncorrelated noise) will significantly increase the residuals. The residuals of the linear fit should remain roughly constant between test and training\n",
    "3. The training RSS for the cubic funcitons should *always* be lower than the training RSS for the linear model regardless of the form of the data.\n",
    "4. The closer the true form is to cubic (i.e. cubic or higher, or convex), the better or cubic model will fit test data. For linear or sub-linear (concave), we should expect the linear form to have a better (smaller) RSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $\\beta_0 = 0$, we may write\n",
    "$$\\hat{y_i} = \\sum_{i'}^n a_{i'}^{(i)} y_{i'},$$\n",
    "where\n",
    "$$a_{i'}^{(i)} = \\dfrac{x_i x_{i'}}{\\sum_{j=1}^n {x_j}^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3.4) says that\n",
    "$$\\hat{\\beta_1}=\\dfrac{\\sum_{i-1}^{n} (x_i - \\bar{x}) (y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2}$$\n",
    "$$\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1} \\bar{x}$$\n",
    "\n",
    "From the above,\n",
    "$$\n",
    "\\begin{align}\n",
    "f(x) & = \\beta_0 + \\beta_1 x \\\\\n",
    "     & = \\bar{y} - \\beta_1 \\bar{x} + \\beta_1 x\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "It is trivial to see, then, that\n",
    "$$\n",
    "\\begin{align}\n",
    "f(\\bar{x}) & = \\bar{y} - \\beta_1 \\bar{x} + \\beta_1 \\bar{x} \\\\\n",
    "           & = \\bar{y}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The least squares line always passes through the point $(\\bar{x}, \\bar{y})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### problem 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not gonna finish this. The bottom line is that if we assume that $\\bar{x} = 0 = \\bar{y}$, then it also follows (provable, but not proven) that\n",
    "$$\n",
    "\\sum{y_i \\hat{y_i}} = \\sum{\\hat{y_i}^2}\n",
    "$$\n",
    "and we are left with the following:\n",
    "\n",
    "then\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "R^2 & = 1 - \\dfrac{RSS}{TSS} \\\\\n",
    "    & = 1 - \\dfrac{\\sum \\left(y_i - \\hat{y_i}\\right)^2}{\\sum {y_i}^2} \\\\\n",
    "    & = \\dfrac{2 \\sum y_i \\hat{y_i} - \\sum {\\hat{y_i}}^2}{\\sum {y_i}^2} \\\\\n",
    "    & = \\dfrac{\\sum {\\hat{y_i}}^2}{\\sum {y_i}^2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "r^2 & = {\\textrm{Cor}(X, Y)}^2 \\\\\n",
    "    & = \\dfrac{\\left(\\sum x_i y_i\\right)^2}{\\sum {x_i}^2 \\sum {y_i}^2} \\\\\n",
    "    & = \\dfrac{\\beta^2}{\\beta^2} \\dfrac{\\left(\\sum x_i y_i\\right)^2}{\\sum {x_i}^2 \\sum {y_i}^2} \\\\\n",
    "    & = \\dfrac{\\left(\\sum \\hat{y_i} y_i\\right)^2}{\\sum {\\hat{y_i}}^2 \\sum {y_i}^2} \\\\\n",
    "    & = \\dfrac{\\left(\\sum {\\hat{y_i}}^2\\right)^2}{\\sum {\\hat{y_i}}^2 \\sum {y_i}^2} \\\\\n",
    "    & = \\dfrac{\\sum {\\hat{y_i}}^2}{\\sum {y_i}^2} \\\\\n",
    "    & = R^2\n",
    "\\end{align}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
